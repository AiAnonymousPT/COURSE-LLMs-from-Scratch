# Meeting 2: Project - Build your GPT tokenizer

We meet again in 2025! 2 months into building LLMs already.

*Mandatory materials are required for everyone to complete before each meeting.*

Optional materials conclude the fundamentals of Deep Learning and Pytorch. 

At this milestone, everyone should have a working level of Deep Learning and Pytorch. This will help to prepare for the full model architecture and pre-training.

Please schedule your time accordingly.

## Materials

- *Mandatory*:
  - Follow the code: [Let's build the GPT Tokenizer](https://youtube.com/watch?v=zduSFxRajkE)
  - Build your own: [GPT Tokenizer](https://github.com/karpathy/minbpe)

<br>

- *Optional*:
  - Deep Learning: [DL with PyTorch Step-by-Step](https://github.com/dvgodoy/PyTorchStepByStep)
  - Word2Vec: [Word2Vec in Pytorch](https://towardsdatascience.com/implementing-word2vec-in-pytorch-skip-gram-model-e6bae040d2fb)

<br>

- *Estimated workload*:
  - mandatory: 20h
  - optional: 20h

&nbsp;

## Meeting Agenda
- Summary, code review
- Group discussion: compare embeddings (BPE, Word2Vec, etc.)
- Q&A


