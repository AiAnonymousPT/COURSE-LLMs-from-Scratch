# Meeting 4: Transformer & GPT Architecture

4 months into building LLMs already! Welcome to the Transformers.

*Mandatory materials are required for everyone to complete before each meeting.*

Optional materials go deeper into the details, and explain the mathematics of Transformers and GPTs.

Please schedule your time accordingly.

## Materials

- *Mandatory*:
  - Chapter 4: GPT architecture
  - Stanford CS25: [Transformers by Karpathy](https://www.youtube.com/watch?v=XfpMkf4rD6E&ab_channel=StanfordOnline)

<br>

- *Optional*:
  - Harvard NLP: [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/#attention-visualization)
  - Visualizing Transformers: [The Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)
  - “A Mathematical Framework for Transformer Circuits”: [[part.1](https://www.oxen.ai/blog/arxiv-dives-a-mathematical-framework-for-transformer-circuits), [part.2](https://www.oxen.ai/blog/arxiv-dives-a-mathematical-framework-for-transformer-circuits-part-two)]

<br>

- *Estimated workload*:
  - mandatory: 30h
  - optional: 20h

&nbsp;

## Meeting Agenda
- Summary, code review
- Group discussion: explain Transformer like I'm 15
- Q&A, debugging