# Meeting 5: Pretraining LLMs

5 months into building LLMs! The training begins.

*Mandatory materials are required for everyone to complete before each meeting.*

Optional materials explore the depths of pretraining LLMs and the current state of the art.

Please schedule your time accordingly.

## Materials

- *Mandatory*:
  - Chapter 5: Pretraining on unlabeled data
  - Appendix D: Adding bells and whistles to the training loop
  - Stanford CS224N|2023 Lecture [Pretraining](https://www.youtube.com/watch?v=DGfCRXuNA2w)

<br>

- *Optional*:
  - Short course: [Pretraining LLMs - DeepLearning.AI ](https://learn.deeplearning.ai/courses/pretraining-llms/lesson/1/introduction)
  - Blog-post: [New Pre-training and Post-training Paradigms](https://sebastianraschka.com/blog/2024/new-llm-pre-training-and-post-training.html)
  
<br>

- *Estimated workload*:
  - mandatory: 30h
  - optional: 20h

&nbsp;

## Meeting Agenda
- Summary, code review
- Group discussion: pretraining pipelines, hardware challenges
- Q&A, debugging